## Chapter 4
# New tools for web-enabled dynamic, interactive visualizations in neuroscience

## Abstract
Datasets in neuroscience are becoming richer and more complex as data is collected on multiple scales, dataset sizes increase, and more subtle questions can be asked of the data. Visualization is an essential tool for understanding these datasets at all stages of analysis, but current practices in visualization are limited in their ability to reflect this richness and complexity. This paper describes a set of web-enabled, dynamic and interactive visualization tools developed for use in electrophysiological studies. These tools were developed to enhance exploratory analysis, checking of raw data and statistical modeling assumptions, and data presentation for large, complex and multi-scale neuroscience data. The paper includes a discussion of the conceptual framework under which the tools were developed and the value of such tools in neuroscience in general.

## 4.1 The purpose of visualization in science
Visualization is a fundamental tool for analysis and communication in science [Cleveland and McGill 1985]. Visualization serves two primary purposes:

First, we use visualization to quickly make multiple, simultaneous comparisons [Tukey 1993, Gelman 2012]. While it is easy to compare and reason about a few numbers, this becomes more difficult as the amount of data or the number of dimensions increases. Visualization eases the cognitive burden on our working memory by efficiently encoding properties of the data into features salient to the human visual perceptual system [Cleveland and McGill 1985, Card et al. 1999]. This involves exploiting easily processed, pre-attentive visual features such as color, line orientation, and line width as well as higher level perceptual grouping such as symmetry and proximity to reduce the search for information [Healy et al. 1996, Card et al. 1999, Fetkete et al. 2008]. By doing so, we are able to more accurately and quickly answer questions about the data compared to tables [Spence and Lewandowsky 1991], solve problems related to the data, and make predictions about future data [more citations].

Second, we use visualization to assist in the understanding and checking of statistical assumptions -- it helps qualify our knowledge and uncertainty about the data and the procedure(s) used to summarize the data. All numerical statistical summaries rely on assumptions about the structure of the data (our implicit/explicit model of the data), but inspection of such summaries alone cannot tell us about violations of those assumptions [Anscombe 1973]. Visualization complements the use of statistical summaries by revealing differences between the expected structure of the data and the observed data [Tukey 1972, 1979]. This is important, from the initial stages of analysis to publication, for revising our assumptions and models and for understanding and communicating where and how often our models fail [Gelman 2004].

A canonical example of this is a set of four datasets known as Anscombe's Quartet [Anscombe 1973].

![Anscombe Quartet](img/Anscombe-image.png)

Each dataset consists of 11 observations of two variables -- *x* and *y*. The *x*- and *y*-variables have the same mean and variance between each dataset. Within each dataset, the *x*- and *y*-variables are also identically correlated and fit by the same regression line. Thus, the numerical statistical summaries are identical. However, visual inspection of the datasets reveal strikingly different structure in each dataset (Figure 1). In particular, the second and third dataset (going clockwise around Figure 1) respectively show a suspiciously quadratic pattern, and a pattern driven by a single datapoint.

## 4.2 Limitations of static visualizations in neuroscience
Static visualizations -- visualizations where the state of the visualization cannot change by user interaction or animation -- have been the *de facto* standard in neuroscience. Static visualizations are used at the early stages of analysis in examining the quality of raw signals (e.g. voltage changes on an electrode, BOLD signals in fMRI), in formulating preliminary hypotheses and in communicating refined analyses in publication. In general, they play a central role in the iterative, sense-making process of data analysis and communication of results.

Advances in technology and computing have made generating static visualizations easier, but those same advances have led to more data, more complex analyses and more nuanced hypotheses [Freeman 2015]. In electrophysiology, implantation of multielectrode arrays with upwards of 100 electrodes are becoming common [Miller and Wilson 2008, Einevoll et al. 2012?, Boyden ????, Siegel et al. 2015] and the number of simultaneously recorded neurons is projected to double every seven years [Stevenson and Kording 2011]. Laminar recordings have also become standard and add a spatial dimension of data per electrode. Whole brain two-photon imaging experiments in zebrafish can yield up to 1.2 TB of data per hour [Freeman 2015]. In fMRI, the amount of data per brain is already high and there have been efforts to scan more than 1000 subjects [Van Dijk et al 2012, etc].

Consequently, analyses are growing in complexity, because with more data, there is greater statistical power to resolve finer differences in the data; we can partition the data into smaller subsets (more dimensions), make comparisons between these subsets, and still not be overcome by noise [Gelman ????]. Advances in computational power have reduced the time to compute these differences and allow for more sophisticated algorithms to detect differences. Thus, we can ask more complicated questions and form more nuanced hypotheses.

An example of this is electrocorticography studies in which grids of intracranial electrodes are placed across wide swaths of cortex. These grids span multiple brain areas and can measure both local field potentials and action potentials (Figure 2a). Given enough data, this allows us to ask questions about the properties at different spatial scales (multiunits, local field potentials, brain region summaries) and how they relate (e.g. correlation and coherence between spatial scales and between brain regions, see Figure 2b). Moreover, we can ask questions about how these change over time and/or relate to experimental conditions. This results in a high-dimensional partitioning of the dataset with many complex interrelations.

So why is this a problem for static visualizations? Complex analyses and hypotheses necessitate an increase in the number of static visualizations or further summarization of the data (dimensionality reduction) to deal with the number of dimensions -- often both. For example, a common visualization of spiking data from a neuron would be a raster plot (Figure 2a) or as a summary -- a histogram (Figure 2c). These are typically visualized with respect to a particular experimental stimulus or event (e.g. a saccade); each event requiring a new visualization. To investigate the firing rate of 1000 neurons in multiple conditions implies visualizations for each neuron (Figure 2d) or aggregation in some form (e.g summarization by brain area, see Figure 2e) once the visualization becomes too ineffective to support perceptual comparison. Because analysis is an iterative process, a typical analysis might require hundreds of visualizations as different sets of experimental conditions are examined or as more data is added.

A large number of static visualizations results in more time spent switching between visualizations, which can not only extend the time to analyze the data, but also has a meaningful impact on our ability to explore and understand the data. For example, Liu and Heer (2014) found that even a 500 millisecond delay between visualizations could reduce the amount of the dataset explored and affect the number of hypotheses and observations formed. Similarly, Brutlag (2009) found that users performed fewer web searches if there was as little as a 200 millisecond delay in the return of search results.

Summarization, while often necessary, can obscure complexity and variability in the data -- as in the case of Anscombe's dataset. It does not obviate the need to understand and check statistical assumptions. This can be a problem with large datasets, where going back and forth between raw data and summaries is difficult because of the amount of data. High-dimensional summaries also require careful checking and understanding of assumptions as more structure in the data is assumed [Gelman 2004] and overfitting becomes a concern. Finally, the sophisticated algorithms used to compute the summaries can result in errors and visualizations again play an important role in catching such errors.

## 4.3 The benefits of web-enabled dynamic, interactive visualizations

### 4.3.1 Interactive visualizations can help us quickly make comparisons and deal with complexity
Interactive visualizations are visualizations where the viewer can manipulate the state of visualization -- typically through the use of a computer mouse, keyboard or touch interface. Interaction triggers state changes that may provide alternate views and data, detail about a particular datapoint, or selection -- a filtered set of the data [Heer and Shneiderman 2012].

For example, [Google Maps](https://www.google.com/maps) is an interactive visualization that provides alternate views by allowing the user to zoom to see map data at different scales (e.g. a single street block, streets in a city, an entire state) and toggle between a satellite overview, a street level view, and the typical map. A user can hover the mouse over a location datapoint to show the name of that location. Clicking on a location selects that datapoint and provides even more detailed information such as user reviews and ratings.

From the Google Maps example, we can see the primary advantages of an interactive visualization over a static visualization. Interactivity allows the user to navigate between alternate views with minimal delay. This allows the user to quickly make comparisons between complex representations of the data such as a map of the neighborhood and a map of the city or between satellite and mapping views. Compare this to paper road atlases with hundreds of pages of static maps. A user can also gain detailed information about individual datapoints without losing the context of the entire map by hovering or clicking on a location (selection). This is particularly advantageous in a rich dataset with multiple levels of information, because instead of obscuring the complexity of the data, the interactivity reveals the complexity in manageable stages.

### 4.3.2 Dynamic visualizations, when combined with interactivity, can help us understand complex data by preserving relationships between data
Dynamics -- also known as animation -- are important in interactive visualizations because they are extremely salient and they preserve the identity of datapoints when the state of the visualization changes (object constancy) [Heer and Robertson 2007]. They give the data analyst another perceptual dimension in which to display information. This can be important when dealing with the dimension of time as well-designed dynamics have been shown to improve accuracy of estimates of change over time [Heer and Robertson 2007] and more complicated visualizations may not have another perceptual dimension in which to display change.

For example, a typical display of a network may encode *nodes* (say corresponding to electrodes implanted in a brain) as circles, and *edges* (corresponding to correlation between electrodes) as lines between the circles. One option to show changes in the network would be to show static "snapshots" of the network as time progresses. While this is fine for a limited number of time points, dynamics can extend the number of time points displayed, because it occupies the same amount of space on the screen.

Dynamics can also be used to preserve a sense of place and context within a complex dataset [Tversky et al. 2002]. In the Google Maps example, clicking on an object centers the map around that object. This centering effect is achieved dynamically, slowly panning to the location in question to preserve the location of other objects relative to the object of interest. Google Maps also uses these dynamics with photos by first zooming in to the map location of the photo, tilting the perspective to imitate a landscape view, then rapidly zooming in on the photo -- informing the user of the correspondence between map and photo. Like interactivity, this multi-stage dynamic helps reveal the complexity of the data in manageable stages.

It must be noted that, like other perceptual encodings of data, dynamics do not always facilitate comprehension. Complicated dynamics, unpredictable dynamics, difficult to perceive dynamics (e.g. due to speed of the animation), or dynamics that violate the user's internal model of the data are all cases where dynamics may not enhance or actually detract from static visualizations [Heer and Robertson 2007]. Careful design is necessary to make sure the dynamics contribute to the understanding of the data.

### 4.3.3 Web-enabled visualizations are familiar and easily shareable
Web browsers are an ideal interface for interactive dynamic visualizations for four reasons: first, web browsers are nearly ubiquitous applications on computers and their usage is familiar to users; second, users are already familiar with dynamic interactive visualizations in form of "web apps" in their browser such as the aforementioned Google Maps; third, because "web apps" are common on the browser, there already exist tools for constructing dynamic, interactive visualizations; and fourth, because these apps are web-enabled, they are easily shareable over the internet. Shareability is important because science is a collaborative process. To maximize shareability, it is vital that communication of results require as little specialized software as possible.

## 4.4 Related Work
There have been previous attempts to make web-enabled dynamic, interactive visualizations in neuroscience. Here we describe several notable visualizations.

The [pycortex webGL MRI viewer](http://gallantlab.org/semanticmovies/) is a web-enabled interactive visualization tool that displays the results from Huth et al. 2012. In the study, Huth and colleagues had subjects view two hours of movie trailers. They then categorized objects and actions in the movies, regressed the categories on the BOLD fMRI signals collected on the subjects watching the movies, and performed a principal components dimensionality reduction to recover a "semantic space". The visualization displays a single subject's color-coded 3D cortical surface representation of this semantic space where similar colors indicate similar categorical representations. The visualization also displays a map of the semantic space itself.

The visualization has interactive controls that allow the user to click on a category to see how it is represented throughout the cortical surface. Conversely, the user can click on a voxel on the cortical surface to see the different categories associated with that voxel. The visualization also provides button controls that dynamically transform the view of the cortical surface (e.g. from inflated to superinflated or from superinflated to flat) and sliders that control the thresholding of the surface colors. The cortical surface can be rotated by dragging the cortical surface. A user can also obtain a permanent web link to a particular voxel of interest by clicking a button. Code for the pycortex viewer is available on [Github](https://github.com/gallantlab/pycortex).

The [Allen Cell Types Database](http://celltypes.brain-map.org/) is a visual interface for a database of neuronal cell types in mouse lateral geniculate nucleus and primary visual cortex. The visualization has several interlinked views including an anatomical cell location view, a parallel coordinate plot of cell features, and a list of cells with more detailed information about the experient and a brief visual summary of its morphology and electrophysiological response pattern to a step current.

Interactive controls allow the user to filter results for layer type, mouse line, and hemisphere. Clicking on cells in the anatomical cell location view, highlights that cell in the list of cells and in the parallel coordinate plot. The parallel coordinate plot provides a way to visually filter by cell features such as FI curve slope or rheobase. Clicking on cell summary brings the user to another web page with more detailed information about that neuron such as the cell's response to different types of currents and comparison to common computational models (e.g. leaky integrate and fire) fit to the data.

The [Allen Mouse Brain Connectivity Atlas](http://connectivity.brain-map.org/) is a similar interface that allows the user to explore the results of 2173 tracer injection experiments on mouse brains. The visualization consists of a 3D cortical surface with labeled injection sites, a brain section image and whole brain projection image corresponding to a specific experiment, and a list of all the projection sites. A user can filter by target or source of the injection or click on an injection site to get the corresponding section and projection image.

Lastly, Freeman and colleagues have incorporated interactive visualizations into their library of distributed computing tools for large scale neuroscience [Freeman et al. 2014]. Their tools -- [Lightning](http://lightning-viz.org/) and [Thunder](http://thunder-project.org/) -- allow for basic chart types such as line graphs, network force diagrams, and heatmaps and custom visualizations to be constructed and updated in real time from data pushed from a server. They demonstrated on whole brain zebrafish recordings how these can be made into interactive visualizations. For example, using [tuning curves](http://research.janelia.org/zebrafish/tuning.html) estimated from moving stimuli in different directions, they visualized the spatial layout of the preferred direction of all neurons in the zebrafish. Mousing over the spatial layout shows the firing rate time course of a neuron in that region. Code for Lightning and Thunder are also available on [Github](https://github.com/freeman-lab).

## 4.5 Design Rationale: goals and challenges for our visualizations

## 4.6 Case Study: RasterVis
RasterVis is a D3-based visualization tool for quickly viewing, grouping and summarizing spike rasters for many neurons.

This tool allows you to:
+ Generate and change between rasters for many neurons.
+ Quickly view rasters aligned to experimental trial events.
+ Add Gaussian-smoothed peristimulus time kernel density estimates with arbitrary smoothing.
+ Group spikes based on experimental factors.

## 4.7 Case Study: SpectraVis

## 4.8 Case Study: glmVis

## 4.9 Future Plans

## References
[#bibliography]: #
